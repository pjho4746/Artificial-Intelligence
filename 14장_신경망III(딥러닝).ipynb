{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyovzc09T0cxWkxMCvbEpk"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1uh9XXyqCp5",
        "outputId": "f5e9dfbf-8d26-4115-9c5d-266656569e2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 5s 9ms/step - loss: 0.0900 - accuracy: 0.2473\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0846 - accuracy: 0.4300\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0790 - accuracy: 0.5052\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0727 - accuracy: 0.5897\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0666 - accuracy: 0.6631\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0611 - accuracy: 0.7121\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0564 - accuracy: 0.7452\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0525 - accuracy: 0.7664\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0492 - accuracy: 0.7835\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0465 - accuracy: 0.7966\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0442 - accuracy: 0.8074\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0423 - accuracy: 0.8155\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0406 - accuracy: 0.8230\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0391 - accuracy: 0.8294\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0378 - accuracy: 0.8347\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0366 - accuracy: 0.8389\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0356 - accuracy: 0.8425\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0346 - accuracy: 0.8461\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0338 - accuracy: 0.8487\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0330 - accuracy: 0.8518\n",
            "테스트 손실값: 0.03167712315917015\n",
            "테스트 정확도: 0.8623999953269958\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "batch_size = 128 # 가중치를 변경하기 전에 처리하는 샘플의 개수\n",
        "num_classes = 10 # 출력 클래스의 개수\n",
        "\n",
        "epochs = 20 # 에포크의 개수\n",
        "# 데이터를 학습 데이터와 테스트 데이터로 나눈다.\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# 입력 이미지를 2차원에서 1차원 벡터로 변경한다.\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "\n",
        "# 입력 이미지의 픽셀 값이 0.0에서 1.0 사이의 값이 되게 한다.\n",
        "x_train = x_train.astype('float32') # (32 비트로, 없어도 실행이 잘 됨)\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# 클래스의 개수에 따라서 하나의 출력 픽셀만이 1이 되게 한다.\n",
        "# 예를 들면 1 0 0 0 0 0 0 0 0 0과 같다.\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# 신경망의 모델을 구축한다.\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(512, activation='sigmoid', input_shape=(784,)))\n",
        "model.add(tf.keras.layers.Dense(num_classes, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "sgd = tf.keras.optimizers.SGD(lr=0.1)\n",
        "\n",
        "# 손실 함수를 제곱 오차 함수로 설정하고 학습 알고리즘은 SGD 방식으로 한다.\n",
        "model.compile(loss='mean_squared_error',\n",
        "optimizer=sgd,\n",
        "metrics=['accuracy'])\n",
        "\n",
        "# 학습을 수행한다.\n",
        "history = model.fit(x_train, y_train,\n",
        "batch_size=batch_size,\n",
        "epochs=epochs)\n",
        "\n",
        "# 학습을 평가한다.\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('테스트 손실값:', score[0])\n",
        "print('테스트 정확도:', score[1])"
      ]
    }
  ]
}